{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:13.017179600Z",
     "start_time": "2023-08-07T12:44:12.987802600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import workspace_path\n",
    "os.chdir(workspace_path.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:13.743972800Z",
     "start_time": "2023-08-07T12:44:13.008068900Z"
    }
   },
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "# 载入算法配置文件\n",
    "cfg = Config.fromfile('./configs/unet/unet-s5-d16_fcn_4xb4-160k_cityscapes-512x1024.py')\n",
    "# 载入数据集配置文件\n",
    "dataset_cfg = Config.fromfile('./configs/_base_/datasets/ZihaoDataset_pipeline.py')\n",
    "# 合并配置文件\n",
    "cfg.merge_from_dict(dataset_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:13.759042400Z",
     "start_time": "2023-08-07T12:44:13.749970500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 类别个数\n",
    "NUM_CLASS = 6\n",
    "cfg.model.data_preprocessor.size = cfg.crop_size\n",
    "cfg.model.data_preprocessor.test_cfg = dict(size_divisor=128)\n",
    "\n",
    "# 单卡训练时，需要把 SyncBN 改成 BN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True) # 只使用GPU时，BN取代SyncBN\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "\n",
    "# 模型 decode/auxiliary 输出头，指定为类别个数\n",
    "cfg.model.decode_head.num_classes = NUM_CLASS\n",
    "cfg.model.auxiliary_head.num_classes = NUM_CLASS\n",
    "\n",
    "# 训练 Batch Size\n",
    "cfg.train_dataloader.batch_size = 4\n",
    "\n",
    "# 结果保存目录\n",
    "cfg.work_dir = 'myfolder/work_dirs/ZihaoDataset-UNet'\n",
    "\n",
    "# 模型保存与日志记录\n",
    "cfg.train_cfg.max_iters = 40000 # 训练迭代次数\n",
    "cfg.train_cfg.val_interval = 500 # 评估模型间隔\n",
    "cfg.default_hooks.logger.interval = 100 # 日志记录间隔\n",
    "cfg.default_hooks.checkpoint.interval = 2500 # 模型权重保存间隔\n",
    "cfg.default_hooks.checkpoint.max_keep_ckpts = 1 # 最多保留几个模型权重\n",
    "cfg.default_hooks.checkpoint.save_best = 'mIoU' # 保留指标最高的模型权重\n",
    "\n",
    "# 随机数种子\n",
    "cfg['randomness'] = dict(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:14.335693500Z",
     "start_time": "2023-08-07T12:44:13.759042400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        1024,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/Watermelon87_Semantic_Seg_Mask/'\n",
      "dataset_type = 'ZihaoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False,\n",
      "        interval=2500,\n",
      "        max_keep_ckpts=1,\n",
      "        save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    auxiliary_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=64,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=128,\n",
      "        in_index=3,\n",
      "        loss_decode=dict(\n",
      "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=6,\n",
      "        num_convs=1,\n",
      "        type='FCNHead'),\n",
      "    backbone=dict(\n",
      "        act_cfg=dict(type='ReLU'),\n",
      "        base_channels=64,\n",
      "        conv_cfg=None,\n",
      "        dec_dilations=(\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "        ),\n",
      "        dec_num_convs=(\n",
      "            2,\n",
      "            2,\n",
      "            2,\n",
      "            2,\n",
      "        ),\n",
      "        downsamples=(\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "        ),\n",
      "        enc_dilations=(\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "        ),\n",
      "        enc_num_convs=(\n",
      "            2,\n",
      "            2,\n",
      "            2,\n",
      "            2,\n",
      "            2,\n",
      "        ),\n",
      "        in_channels=3,\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=False,\n",
      "        num_stages=5,\n",
      "        strides=(\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "        ),\n",
      "        type='UNet',\n",
      "        upsample_cfg=dict(type='InterpConv'),\n",
      "        with_cp=False),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        test_cfg=dict(size_divisor=128),\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=64,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=64,\n",
      "        in_index=4,\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=6,\n",
      "        num_convs=1,\n",
      "        type='FCNHead'),\n",
      "    pretrained=None,\n",
      "    test_cfg=dict(crop_size=256, mode='whole', stride=170),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=None,\n",
      "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0001,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=0)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=40000, type='IterBasedTrainLoop', val_interval=500)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='img_dir/train', seg_map_path='ann_dir/train'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'myfolder/work_dirs/ZihaoDataset-UNet'\n"
     ]
    }
   ],
   "source": [
    "# 查看最终的config配置文件\n",
    "print(cfg.pretty_text)\n",
    "# 保存最终的config配置文件\n",
    "cfg.dump('myFolder/config/ZihaoDataset_UNet_20230712.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLabV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:14.398486600Z",
     "start_time": "2023-08-07T12:44:14.339701700Z"
    }
   },
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "# 载入算法配置文件\n",
    "cfg = Config.fromfile('./configs/deeplabv3plus/deeplabv3plus_r101-d8_4xb4-80k_ade20k-512x512.py')\n",
    "# 载入数据集配置文件\n",
    "dataset_cfg = Config.fromfile('./configs/_base_/datasets/ZihaoDataset_pipeline.py')\n",
    "# 合并配置文件\n",
    "cfg.merge_from_dict(dataset_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:14.412957700Z",
     "start_time": "2023-08-07T12:44:14.401749200Z"
    }
   },
   "outputs": [],
   "source": [
    "# 类别个数\n",
    "NUM_CLASS = 6\n",
    "\n",
    "cfg.crop_size = (512, 512)\n",
    "cfg.model.data_preprocessor.size = cfg.crop_size\n",
    "\n",
    "# 单卡训练时，需要把 SyncBN 改成 BN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "\n",
    "# 模型 decode/auxiliary 输出头，指定为类别个数\n",
    "cfg.model.decode_head.num_classes = NUM_CLASS\n",
    "cfg.model.auxiliary_head.num_classes = NUM_CLASS\n",
    "\n",
    "# 训练 Batch Size\n",
    "cfg.train_dataloader.batch_size = 4\n",
    "\n",
    "# 结果保存目录\n",
    "cfg.work_dir = 'myfolder/work_dirs/ZihaoDataset-DeepLabV3plus'\n",
    "\n",
    "# 模型保存与日志记录\n",
    "cfg.train_cfg.max_iters = 20000 # 训练迭代次数\n",
    "cfg.train_cfg.val_interval = 500 # 评估模型间隔\n",
    "cfg.default_hooks.logger.interval = 100 # 日志记录间隔\n",
    "cfg.default_hooks.checkpoint.interval = 2500 # 模型权重保存间隔\n",
    "cfg.default_hooks.checkpoint.max_keep_ckpts = 1 # 最多保留几个模型权重\n",
    "cfg.default_hooks.checkpoint.save_best = 'mIoU' # 保留指标最高的模型权重\n",
    "\n",
    "# 随机数种子\n",
    "cfg['randomness'] = dict(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:14.884403700Z",
     "start_time": "2023-08-07T12:44:14.490416900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/Watermelon87_Semantic_Seg_Mask/'\n",
      "dataset_type = 'ZihaoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False,\n",
      "        interval=2500,\n",
      "        max_keep_ckpts=1,\n",
      "        save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    auxiliary_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=256,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=1024,\n",
      "        in_index=2,\n",
      "        loss_decode=dict(\n",
      "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=6,\n",
      "        num_convs=1,\n",
      "        type='FCNHead'),\n",
      "    backbone=dict(\n",
      "        contract_dilation=True,\n",
      "        depth=101,\n",
      "        dilations=(\n",
      "            1,\n",
      "            1,\n",
      "            2,\n",
      "            4,\n",
      "        ),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=False,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        strides=(\n",
      "            1,\n",
      "            2,\n",
      "            1,\n",
      "            1,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNetV1c'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        c1_channels=48,\n",
      "        c1_in_channels=256,\n",
      "        channels=512,\n",
      "        dilations=(\n",
      "            1,\n",
      "            12,\n",
      "            24,\n",
      "            36,\n",
      "        ),\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=2048,\n",
      "        in_index=3,\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=6,\n",
      "        type='DepthwiseSeparableASPPHead'),\n",
      "    pretrained='open-mmlab://resnet101_v1c',\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=None,\n",
      "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=80000,\n",
      "        eta_min=0.0001,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=0)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=20000, type='IterBasedTrainLoop', val_interval=500)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='img_dir/train', seg_map_path='ann_dir/train'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'myfolder/ZihaoDataset-DeepLabV3plus'\n"
     ]
    }
   ],
   "source": [
    "# 查看最终的config配置文件\n",
    "print(cfg.pretty_text)\n",
    "# 保存最终的config配置文件\n",
    "cfg.dump('myFolder/config/ZihaoDataset_DeepLabV3plus_20230712.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:14.957773300Z",
     "start_time": "2023-08-07T12:44:14.883397800Z"
    }
   },
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "# 载入算法配置文件\n",
    "cfg = Config.fromfile('./configs/pspnet/pspnet_r50-d8_4xb2-40k_cityscapes-512x1024.py')\n",
    "# 载入数据集配置文件\n",
    "dataset_cfg = Config.fromfile('./configs/_base_/datasets/ZihaoDataset_pipeline.py')\n",
    "# 合并配置文件\n",
    "cfg.merge_from_dict(dataset_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:14.973637800Z",
     "start_time": "2023-08-07T12:44:14.958782200Z"
    }
   },
   "outputs": [],
   "source": [
    "# 类别个数\n",
    "NUM_CLASS = 6\n",
    "\n",
    "cfg.model.data_preprocessor.size = cfg.crop_size\n",
    "\n",
    "# 单卡训练时，需要把 SyncBN 改成 BN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "\n",
    "# 模型 decode/auxiliary 输出头，指定为类别个数\n",
    "cfg.model.decode_head.num_classes = NUM_CLASS\n",
    "cfg.model.auxiliary_head.num_classes = NUM_CLASS\n",
    "\n",
    "# 训练 Batch Size\n",
    "cfg.train_dataloader.batch_size = 4\n",
    "\n",
    "# 结果保存目录\n",
    "cfg.work_dir = 'myfolder/work_dirs/ZihaoDataset-PSPNet'\n",
    "\n",
    "# 模型保存与日志记录\n",
    "cfg.train_cfg.max_iters = 40000 # 训练迭代次数\n",
    "cfg.train_cfg.val_interval = 500 # 评估模型间隔\n",
    "cfg.default_hooks.logger.interval = 100 # 日志记录间隔\n",
    "cfg.default_hooks.checkpoint.interval = 2500 # 模型权重保存间隔\n",
    "cfg.default_hooks.checkpoint.max_keep_ckpts = 1 # 最多保留几个模型权重\n",
    "cfg.default_hooks.checkpoint.save_best = 'mIoU' # 保留指标最高的模型权重\n",
    "\n",
    "# 随机数种子\n",
    "cfg['randomness'] = dict(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:15.411877500Z",
     "start_time": "2023-08-07T12:44:14.973637800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        1024,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/Watermelon87_Semantic_Seg_Mask/'\n",
      "dataset_type = 'ZihaoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False,\n",
      "        interval=2500,\n",
      "        max_keep_ckpts=1,\n",
      "        save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    auxiliary_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=256,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=1024,\n",
      "        in_index=2,\n",
      "        loss_decode=dict(\n",
      "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=6,\n",
      "        num_convs=1,\n",
      "        type='FCNHead'),\n",
      "    backbone=dict(\n",
      "        contract_dilation=True,\n",
      "        depth=50,\n",
      "        dilations=(\n",
      "            1,\n",
      "            1,\n",
      "            2,\n",
      "            4,\n",
      "        ),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=False,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        strides=(\n",
      "            1,\n",
      "            2,\n",
      "            1,\n",
      "            1,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNetV1c'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=512,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=2048,\n",
      "        in_index=3,\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=6,\n",
      "        pool_scales=(\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "            6,\n",
      "        ),\n",
      "        type='PSPHead'),\n",
      "    pretrained='open-mmlab://resnet50_v1c',\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=None,\n",
      "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=40000,\n",
      "        eta_min=0.0001,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=0)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=40000, type='IterBasedTrainLoop', val_interval=500)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='img_dir/train', seg_map_path='ann_dir/train'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'myfolder/ZihaoDataset-PSPNet'\n"
     ]
    }
   ],
   "source": [
    "# 查看最终的config配置文件\n",
    "print(cfg.pretty_text)\n",
    "# 保存最终的config配置文件\n",
    "cfg.dump('myFolder/config/ZihaoDataset_PSPNet_20230712.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast-SCNN\n",
    "推荐使用的轻量化语义分割模型有: Fast-SCNN DDRNet PIDNet STDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:15.473579400Z",
     "start_time": "2023-08-07T12:44:15.413498400Z"
    }
   },
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "# 载入算法配置文件\n",
    "cfg = Config.fromfile('./configs/fastscnn/fast_scnn_8xb4-160k_cityscapes-512x1024.py')\n",
    "# 载入数据集配置文件\n",
    "dataset_cfg = Config.fromfile('./configs/_base_/datasets/ZihaoDataset_pipeline.py')\n",
    "# 合并配置文件\n",
    "cfg.merge_from_dict(dataset_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:15.489806100Z",
     "start_time": "2023-08-07T12:44:15.476579700Z"
    }
   },
   "outputs": [],
   "source": [
    "# 类别个数\n",
    "NUM_CLASS = 6\n",
    "\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True) # 只使用GPU时，BN取代SyncBN\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head[0].norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head[1].norm_cfg = cfg.norm_cfg\n",
    "\n",
    "# 模型 decode/auxiliary 输出头，指定为类别个数\n",
    "cfg.model.decode_head.num_classes = NUM_CLASS\n",
    "cfg.model.auxiliary_head[0]['num_classes'] = NUM_CLASS\n",
    "cfg.model.auxiliary_head[1]['num_classes'] = NUM_CLASS\n",
    "\n",
    "cfg.train_dataloader.batch_size = 4\n",
    "\n",
    "cfg.test_dataloader = cfg.val_dataloader\n",
    "\n",
    "# 结果保存目录\n",
    "cfg.work_dir = 'myfolder/work_dirs/ZihaoDataset-FastSCNN'\n",
    "\n",
    "cfg.train_cfg.max_iters = 30000 # 训练迭代次数\n",
    "cfg.train_cfg.val_interval = 500 # 评估模型间隔\n",
    "cfg.default_hooks.logger.interval = 100 # 日志记录间隔\n",
    "cfg.default_hooks.checkpoint.interval = 2500 # 模型权重保存间隔\n",
    "cfg.default_hooks.checkpoint.max_keep_ckpts = 2 # 最多保留几个模型权重\n",
    "cfg.default_hooks.checkpoint.save_best = 'mIoU' # 保留指标最高的模型权重\n",
    "\n",
    "# 随机数种子\n",
    "cfg['randomness'] = dict(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:16.058524400Z",
     "start_time": "2023-08-07T12:44:15.490807400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        1024,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/Watermelon87_Semantic_Seg_Mask/'\n",
      "dataset_type = 'ZihaoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False,\n",
      "        interval=2500,\n",
      "        max_keep_ckpts=2,\n",
      "        save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    auxiliary_head=[\n",
      "        dict(\n",
      "            align_corners=False,\n",
      "            channels=32,\n",
      "            concat_input=False,\n",
      "            in_channels=128,\n",
      "            in_index=-2,\n",
      "            loss_decode=dict(\n",
      "                loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "            num_classes=6,\n",
      "            num_convs=1,\n",
      "            type='FCNHead'),\n",
      "        dict(\n",
      "            align_corners=False,\n",
      "            channels=32,\n",
      "            concat_input=False,\n",
      "            in_channels=64,\n",
      "            in_index=-3,\n",
      "            loss_decode=dict(\n",
      "                loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "            num_classes=6,\n",
      "            num_convs=1,\n",
      "            type='FCNHead'),\n",
      "    ],\n",
      "    backbone=dict(\n",
      "        align_corners=False,\n",
      "        downsample_dw_channels=(\n",
      "            32,\n",
      "            48,\n",
      "        ),\n",
      "        fusion_out_channels=128,\n",
      "        global_block_channels=(\n",
      "            64,\n",
      "            96,\n",
      "            128,\n",
      "        ),\n",
      "        global_block_strides=(\n",
      "            2,\n",
      "            2,\n",
      "            1,\n",
      "        ),\n",
      "        global_in_channels=64,\n",
      "        global_out_channels=128,\n",
      "        higher_in_channels=64,\n",
      "        lower_in_channels=128,\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "        ),\n",
      "        type='FastSCNN'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            1024,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=128,\n",
      "        concat_input=False,\n",
      "        in_channels=128,\n",
      "        in_index=-1,\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=6,\n",
      "        type='DepthwiseSeparableFCNHead'),\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=None,\n",
      "    optimizer=dict(lr=0.12, momentum=0.9, type='SGD', weight_decay=4e-05),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.12, momentum=0.9, type='SGD', weight_decay=4e-05)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0001,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=0)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=30000, type='IterBasedTrainLoop', val_interval=500)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='img_dir/train', seg_map_path='ann_dir/train'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'myfolder/ZihaoDataset-FastSCNN'\n"
     ]
    }
   ],
   "source": [
    "# 查看最终的config配置文件\n",
    "print(cfg.pretty_text)\n",
    "# 保存最终的config配置文件\n",
    "cfg.dump('myFolder/config/ZihaoDataset_FastSCNN_20230712.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:16.110081600Z",
     "start_time": "2023-08-07T12:44:16.050997500Z"
    }
   },
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "# 载入算法配置文件\n",
    "cfg = Config.fromfile('./configs/segformer/segformer_mit-b5_8xb2-160k_ade20k-512x512.py')\n",
    "# 载入数据集配置文件\n",
    "dataset_cfg = Config.fromfile('./configs/_base_/datasets/ZihaoDataset_pipeline.py')\n",
    "# 合并配置文件\n",
    "cfg.merge_from_dict(dataset_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:16.125086500Z",
     "start_time": "2023-08-07T12:44:16.109082100Z"
    }
   },
   "outputs": [],
   "source": [
    "# 类别个数\n",
    "NUM_CLASS = 6\n",
    "\n",
    "# 单卡训练时，需要把 SyncBN 改成 BN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True) # 只使用GPU时，BN取代SyncBN\n",
    "cfg.model.data_preprocessor.size = cfg.crop_size\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "\n",
    "# 模型 decode/auxiliary 输出头，指定为类别个数\n",
    "cfg.model.decode_head.num_classes = NUM_CLASS\n",
    "\n",
    "# 训练 Batch Size\n",
    "cfg.train_dataloader.batch_size = 4\n",
    "\n",
    "# 结果保存目录\n",
    "cfg.work_dir = 'myfolder/work_dirs/ZihaoDataset-Segformer'\n",
    "\n",
    "cfg.train_cfg.max_iters = 40000 # 训练迭代次数\n",
    "cfg.train_cfg.val_interval = 500 # 评估模型间隔\n",
    "cfg.default_hooks.logger.interval = 100 # 日志记录间隔\n",
    "cfg.default_hooks.checkpoint.interval = 2500 # 模型权重保存间隔\n",
    "cfg.default_hooks.checkpoint.max_keep_ckpts = 2 # 最多保留几个模型权重\n",
    "cfg.default_hooks.checkpoint.save_best = 'mIoU' # 保留指标最高的模型权重\n",
    "\n",
    "# 随机数种子\n",
    "cfg['randomness'] = dict(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T12:44:16.688037600Z",
     "start_time": "2023-08-07T12:44:16.126086500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/Watermelon87_Semantic_Seg_Mask/'\n",
      "dataset_type = 'ZihaoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False,\n",
      "        interval=2500,\n",
      "        max_keep_ckpts=2,\n",
      "        save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=64,\n",
      "        in_channels=3,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth',\n",
      "            type='Pretrained'),\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            1,\n",
      "            2,\n",
      "            5,\n",
      "            8,\n",
      "        ],\n",
      "        num_layers=[\n",
      "            3,\n",
      "            6,\n",
      "            40,\n",
      "            3,\n",
      "        ],\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_sizes=[\n",
      "            7,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "        ],\n",
      "        qkv_bias=True,\n",
      "        sr_ratios=[\n",
      "            8,\n",
      "            4,\n",
      "            2,\n",
      "            1,\n",
      "        ],\n",
      "        type='MixVisionTransformer'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=256,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=[\n",
      "            64,\n",
      "            128,\n",
      "            320,\n",
      "            512,\n",
      "        ],\n",
      "        in_index=[\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ],\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=6,\n",
      "        type='SegformerHead'),\n",
      "    pretrained=None,\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=6e-05, type='AdamW', weight_decay=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            head=dict(lr_mult=10.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            pos_block=dict(decay_mult=0.0))),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1500, start_factor=1e-06,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1500,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=0)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=40000, type='IterBasedTrainLoop', val_interval=500)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='img_dir/train', seg_map_path='ann_dir/train'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='data/Watermelon87_Semantic_Seg_Mask/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ZihaoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'myfolder/ZihaoDataset-Segformer'\n"
     ]
    }
   ],
   "source": [
    "# 查看最终的config配置文件\n",
    "print(cfg.pretty_text)\n",
    "# 保存最终的config配置文件\n",
    "cfg.dump('myFolder/config/ZihaoDataset_Segformer_20230712.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
